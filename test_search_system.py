#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Milvus ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì—…ë¡œë“œëœ amnesty_qa ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ RAG ê²€ìƒ‰ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import sys
import logging
import time
import statistics
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(project_root, 'src')
sys.path.insert(0, project_root)
sys.path.insert(0, src_path)

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from vectordb.milvus_client import MilvusClient
except ImportError:
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë‹¤ì‹œ ì‹œë„
    sys.path.insert(0, os.path.join(project_root, 'src', 'vectordb'))
    from milvus_client import MilvusClient

from sentence_transformers import SentenceTransformer
import yaml

# ê°„ë‹¨í•œ Config í´ë˜ìŠ¤ ì •ì˜
class Config:
    def __init__(self):
        self.config_data = {
            'milvus': {
                'host': 'localhost',
                'port': 19530,
                'index_type': 'HNSW',
                'metric_type': 'COSINE'
            }
        }
        
        # config.yaml íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
        config_path = os.path.join(project_root, 'config.yaml')
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    loaded_config = yaml.safe_load(f)
                    if loaded_config:
                        self.config_data.update(loaded_config)
            except Exception as e:
                logging.warning(f"config.yaml ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    @property
    def milvus(self):
        return self.config_data.get('milvus', {})

# ë¡œê±° ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("search_test")

class SearchSystemTester:
    def __init__(self):
        """ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        try:
            # Config ë° Milvus í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.config = Config()
            self.milvus_client = MilvusClient(self.config)
            
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ì—…ë¡œë“œì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©)
            model_name = 'sentence-transformers/all-MiniLM-L6-v2'
            logger.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
            self.embedding_model = SentenceTransformer(model_name)
            
            self.collection_name = "test_amnesty_qa"
            
            logger.info("ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤í„° ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def test_collection_info(self):
        """ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸"""
        logger.info("=== ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ===")
        
        # ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not self.milvus_client.has_collection(self.collection_name):
            logger.error(f"ì»¬ë ‰ì…˜ '{self.collection_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False
        
        # ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´
        stats = self.milvus_client.get_collection_stats(self.collection_name)
        count = self.milvus_client.count(self.collection_name)
        
        logger.info(f"ì»¬ë ‰ì…˜ '{self.collection_name}' ì •ë³´:")
        logger.info(f"  - ì´ ë¬¸ì„œ ìˆ˜: {count}")
        logger.info(f"  - ìŠ¤í‚¤ë§ˆ: {stats.get('schema', 'N/A')}")
        
        return True

    def test_search_queries(self):
        """ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ê²€ìƒ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ===")
        test_start_time = time.time()
        
        test_queries = [
            "What are human rights?",
            "freedom of expression",
            "torture prevention",
            "êµìœ¡ ê¶Œë¦¬",  # í•œêµ­ì–´ í…ŒìŠ¤íŠ¸
            "democracy and justice",
            "international law",
            "refugee protection"
        ]
        
        successful_queries = 0
        query_performance = []
        similarity_scores = []
        
        for i, query in enumerate(test_queries, 1):
            logger.info(f"\ní…ŒìŠ¤íŠ¸ {i}: '{query}'")
            query_start_time = time.time()
            
            try:
                # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
                embedding_start = time.time()
                query_embedding = self.embedding_model.encode([query])[0]
                embedding_time = time.time() - embedding_start
                
                # Milvus ê²€ìƒ‰ ì‹¤í–‰
                search_start = time.time()
                results = self.milvus_client.search(
                    collection_name=self.collection_name,
                    query_vector=query_embedding.tolist() if hasattr(query_embedding, 'tolist') else list(query_embedding),
                    top_k=3,
                    output_fields=['text', 'chunk_type', 'source', 'article_title']
                )
                search_time = time.time() - search_start
                total_query_time = time.time() - query_start_time
                
                query_performance.append({
                    'query': query,
                    'embedding_time': embedding_time,
                    'search_time': search_time,
                    'total_time': total_query_time,
                    'result_count': len(results) if results else 0
                })
                
                if results and len(results) > 0:
                    logger.info(f"  ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ (ê²€ìƒ‰ì‹œê°„: {search_time:.3f}ì´ˆ)")
                    
                    # ìœ ì‚¬ë„ ì ìˆ˜ ìˆ˜ì§‘ ë° ë¶„ì„
                    query_scores = []
                    for j, result in enumerate(results, 1):
                        score = result.get('score', 0)
                        text = result.get('text', '')[:100]
                        chunk_type = result.get('chunk_type', 'unknown')
                        
                        query_scores.append(score)
                        similarity_scores.append(score)
                        logger.info(f"    {j}. [{chunk_type}] {text}... (ìœ ì‚¬ë„: {score:.3f})")
                    
                    # ì¿¼ë¦¬ë³„ ìœ ì‚¬ë„ í†µê³„
                    if query_scores:
                        avg_score = statistics.mean(query_scores)
                        max_score = max(query_scores)
                        min_score = min(query_scores)
                        logger.info(f"  ìœ ì‚¬ë„ í†µê³„ - í‰ê· : {avg_score:.3f}, ìµœê³ : {max_score:.3f}, ìµœì €: {min_score:.3f}")
                    
                    successful_queries += 1
                else:
                    logger.warning(f"  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (ê²€ìƒ‰ì‹œê°„: {search_time:.3f}ì´ˆ)")
                    # ê²°ê³¼ê°€ ì—†ì–´ë„ ê²€ìƒ‰ ìì²´ëŠ” ì„±ê³µí•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
                    successful_queries += 1
                
                logger.debug(f"  ì„±ëŠ¥ ì„¸ë¶€ì‚¬í•­ - ì„ë² ë”©: {embedding_time:.3f}ì´ˆ, ê²€ìƒ‰: {search_time:.3f}ì´ˆ, ì´ì‹œê°„: {total_query_time:.3f}ì´ˆ")
                    
            except Exception as e:
                error_time = time.time() - query_start_time
                logger.error(f"  ê²€ìƒ‰ ì˜¤ë¥˜: {e} (ì˜¤ë¥˜ë°œìƒì‹œê°„: {error_time:.3f}ì´ˆ)")
                logger.error(f"  ë””ë²„ê¹… íŒíŠ¸: ì¿¼ë¦¬ '{query}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë˜ëŠ” Milvus ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë§Œ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
                
        # ì „ì²´ ì„±ëŠ¥ ìš”ì•½
        test_total_time = time.time() - test_start_time
        
        if query_performance:
            avg_embedding_time = statistics.mean([p['embedding_time'] for p in query_performance])
            avg_search_time = statistics.mean([p['search_time'] for p in query_performance])
            avg_total_time = statistics.mean([p['total_time'] for p in query_performance])
            
            logger.info(f"\nê²€ìƒ‰ ì¿¼ë¦¬ ì„±ëŠ¥ ìš”ì•½:")
            logger.info(f"  - í‰ê·  ì„ë² ë”© ì‹œê°„: {avg_embedding_time:.3f}ì´ˆ")
            logger.info(f"  - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time:.3f}ì´ˆ")
            logger.info(f"  - í‰ê·  ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œê°„: {avg_total_time:.3f}ì´ˆ")
            logger.info(f"  - ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {test_total_time:.3f}ì´ˆ")
            
        if similarity_scores:
            logger.info(f"  - ì „ì²´ ìœ ì‚¬ë„ í†µê³„: í‰ê·  {statistics.mean(similarity_scores):.3f}, "
                       f"í‘œì¤€í¸ì°¨ {statistics.stdev(similarity_scores) if len(similarity_scores) > 1 else 0:.3f}")
                
        logger.info(f"ê²€ìƒ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸: {successful_queries}/{len(test_queries)}ê°œ ì„±ê³µ")
        return successful_queries == len(test_queries)

    def test_filtered_search(self):
        """í•„í„°ë§ëœ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        logger.info("=== í•„í„°ë§ëœ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
        test_start_time = time.time()
        
        query = "human rights"
        embedding_start = time.time()
        query_embedding = self.embedding_model.encode([query])[0]
        embedding_time = time.time() - embedding_start
        logger.info(f"ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹œê°„: {embedding_time:.3f}ì´ˆ")
        
        # chunk_typeë³„ í•„í„°ë§ í…ŒìŠ¤íŠ¸
        chunk_types = ['question', 'answer', 'title']
        successful_searches = 0
        search_results_summary = {}
        filter_performance = []
        
        for chunk_type in chunk_types:
            logger.info(f"\n'{chunk_type}' íƒ€ì… í•„í„°ë§ ê²€ìƒ‰:")
            search_start_time = time.time()
            
            try:
                filter_expr = f"chunk_type == '{chunk_type}'"
                
                results = self.milvus_client.search(
                    collection_name=self.collection_name,
                    query_vector=query_embedding.tolist() if hasattr(query_embedding, 'tolist') else list(query_embedding),
                    top_k=3,
                    filter_expr=filter_expr,
                    output_fields=['text', 'chunk_type', 'source']
                )
                
                search_time = time.time() - search_start_time
                filter_performance.append({
                    'chunk_type': chunk_type,
                    'search_time': search_time,
                    'result_count': len(results) if results else 0
                })
                
                if results and len(results) > 0:
                    logger.info(f"  ê²°ê³¼: {len(results)}ê°œ (ê²€ìƒ‰ì‹œê°„: {search_time:.3f}ì´ˆ)")
                    chunk_scores = []
                    for j, result in enumerate(results, 1):
                        score = result.get('score', 0)
                        text = result.get('text', '')[:80]
                        chunk_scores.append(score)
                        logger.info(f"    {j}. {text}... (ìœ ì‚¬ë„: {score:.3f})")
                    
                    if chunk_scores:
                        avg_score = statistics.mean(chunk_scores)
                        logger.info(f"  í‰ê·  ìœ ì‚¬ë„: {avg_score:.3f}")
                    
                    search_results_summary[chunk_type] = len(results)
                else:
                    if chunk_type == 'title':
                        logger.warning(f"  '{chunk_type}' íƒ€ì… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì˜ˆìƒëœ ìƒí™© - ì •ìƒ) (ê²€ìƒ‰ì‹œê°„: {search_time:.3f}ì´ˆ)")
                    else:
                        logger.info(f"  '{chunk_type}' íƒ€ì… ê²°ê³¼ ì—†ìŒ (ê²€ìƒ‰ì‹œê°„: {search_time:.3f}ì´ˆ)")
                    search_results_summary[chunk_type] = 0
                    
                # ê²€ìƒ‰ ìì²´ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼ (ê²°ê³¼ ìœ ë¬´ì™€ ë¬´ê´€)
                successful_searches += 1
                    
            except Exception as e:
                search_time = time.time() - search_start_time
                logger.error(f"  '{chunk_type}' íƒ€ì… í•„í„°ë§ ê²€ìƒ‰ ì‹¤ì œ ì˜¤ë¥˜: {e} (ì˜¤ë¥˜ë°œìƒì‹œê°„: {search_time:.3f}ì´ˆ)")
                logger.error(f"  ë””ë²„ê¹… íŒíŠ¸: chunk_type='{chunk_type}' í•„í„° ì¡°ê±´ì„ í™•ì¸í•˜ê±°ë‚˜ ì»¬ë ‰ì…˜ ìŠ¤í‚¤ë§ˆë¥¼ ì ê²€í•˜ì„¸ìš”.")
                search_results_summary[chunk_type] = "ERROR"
                filter_performance.append({
                    'chunk_type': chunk_type,
                    'search_time': search_time,
                    'result_count': 'ERROR'
                })
                # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë§Œ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
        
        # ì „ì²´ í•„í„°ë§ ê²€ìƒ‰ ì„±ëŠ¥ ìš”ì•½
        test_total_time = time.time() - test_start_time
        
        if filter_performance:
            successful_filter_searches = [p for p in filter_performance if p['result_count'] != 'ERROR']
            if successful_filter_searches:
                avg_filter_time = statistics.mean([p['search_time'] for p in successful_filter_searches])
                total_results = sum([p['result_count'] for p in successful_filter_searches])
                
                logger.info(f"\ní•„í„°ë§ ê²€ìƒ‰ ì„±ëŠ¥ ìš”ì•½:")
                logger.info(f"  - í‰ê·  í•„í„° ê²€ìƒ‰ ì‹œê°„: {avg_filter_time:.3f}ì´ˆ")
                logger.info(f"  - ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {test_total_time:.3f}ì´ˆ")
                logger.info(f"  - ì´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {total_results}ê°œ")
        
        # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ë¡œê¹…
        logger.info(f"\ní•„í„°ë§ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:")
        for chunk_type, count in search_results_summary.items():
            if count == "ERROR":
                logger.error(f"  - {chunk_type}: ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ")
            elif count == 0:
                if chunk_type == 'title':
                    logger.info(f"  - {chunk_type}: 0ê°œ (ë°ì´í„° ì—†ìŒ - ì •ìƒ)")
                else:
                    logger.info(f"  - {chunk_type}: 0ê°œ")
            else:
                logger.info(f"  - {chunk_type}: {count}ê°œ")
                
        logger.info(f"í•„í„°ë§ëœ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: {successful_searches}/{len(chunk_types)}ê°œ ì„±ê³µ")
        return successful_searches == len(chunk_types)

    def test_rag_pipeline(self):
        """RAG íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸"""
        logger.info("=== RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ===")
        
        user_question = "How can individuals protect human rights?"
        logger.info(f"ì‚¬ìš©ì ì§ˆë¬¸: {user_question}")
        
        try:
            # 1. ì§ˆë¬¸ ì„ë² ë”©
            question_embedding = self.embedding_model.encode([user_question])[0]
            
            # 2. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            search_results = self.milvus_client.search(
                collection_name=self.collection_name,
                query_vector=question_embedding.tolist() if hasattr(question_embedding, 'tolist') else list(question_embedding),
                top_k=5,
                output_fields=['text', 'chunk_type', 'source', 'article_title']
            )
            
            if search_results and len(search_results) > 0:
                logger.info(f"ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ: {len(search_results)}ê°œ")
                
                # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                context_parts = []
                for i, result in enumerate(search_results, 1):
                    text = result.get('text', '')
                    chunk_type = result.get('chunk_type', 'unknown')
                    score = result.get('score', 0)
                    
                    context_parts.append(f"[{chunk_type}] {text}")
                    logger.info(f"  {i}. [{chunk_type}] {text[:100]}... (ìœ ì‚¬ë„: {score:.3f})")
                
                # 4. ìµœì¢… ì»¨í…ìŠ¤íŠ¸
                context = "\n\n".join(context_parts)
                logger.info(f"\nêµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)} ë¬¸ì")
                
                # 5. RAG ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” LLMì— ì „ë‹¬)
                prompt = f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {user_question}

ë‹µë³€:"""
                
                logger.info("âœ… RAG íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì™„ë£Œ")
                logger.info(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
                
                return True
            else:
                logger.warning("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            logger.error(f"RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return False

    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("=== Milvus ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        overall_start_time = time.time()
        
        test_results = []
        
        # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        tests = [
            ("ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸", self.test_collection_info),
            ("ê²€ìƒ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸", self.test_search_queries),
            ("í•„í„°ë§ëœ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸", self.test_filtered_search),
            ("RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸", self.test_rag_pipeline)
        ]
        
        test_performance = []
        
        for test_name, test_func in tests:
            try:
                logger.info(f"\n{'='*50}")
                test_start = time.time()
                result = test_func()
                test_time = time.time() - test_start
                
                test_results.append((test_name, result))
                test_performance.append({
                    'name': test_name,
                    'time': test_time,
                    'success': result
                })
                
                status = "ì„±ê³µ" if result else "ì‹¤íŒ¨"
                logger.info(f"{test_name}: {status} (ì‹¤í–‰ì‹œê°„: {test_time:.3f}ì´ˆ)")
                
            except Exception as e:
                test_time = time.time() - test_start if 'test_start' in locals() else 0
                logger.error(f"{test_name} ì‹¤í–‰ ì˜¤ë¥˜: {e} (ì˜¤ë¥˜ë°œìƒì‹œê°„: {test_time:.3f}ì´ˆ)")
                logger.error(f"ë””ë²„ê¹… íŒíŠ¸: '{test_name}' í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì‹œìŠ¤í…œ ìƒíƒœì™€ ì˜ì¡´ì„±ì„ í™•ì¸í•˜ì„¸ìš”.")
                test_results.append((test_name, False))
                test_performance.append({
                    'name': test_name,
                    'time': test_time,
                    'success': False
                })
        
        overall_time = time.time() - overall_start_time
        
        
        # ê²°ê³¼ ìš”ì•½
        logger.info(f"\n{'='*50}")
        logger.info("=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
        
        success_count = 0
        failed_tests = []
        for test_name, result in test_results:
            status = "âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"
            logger.info(f"  {test_name}: {status}")
            if result:
                success_count += 1
            else:
                failed_tests.append(test_name)
        
        # ì„±ëŠ¥ ìš”ì•½
        if test_performance:
            successful_tests = [t for t in test_performance if t['success']]
            failed_test_times = [t for t in test_performance if not t['success']]
            
            logger.info(f"\n=== ì„±ëŠ¥ ìš”ì•½ ===")
            logger.info(f"  - ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œê°„: {overall_time:.3f}ì´ˆ")
            
            if successful_tests:
                avg_success_time = statistics.mean([t['time'] for t in successful_tests])
                logger.info(f"  - ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ í‰ê·  ì‹œê°„: {avg_success_time:.3f}ì´ˆ")
                
            for test in test_performance:
                status = "âœ…" if test['success'] else "âŒ"
                logger.info(f"    {status} {test['name']}: {test['time']:.3f}ì´ˆ")
        
        total_tests = len(test_results)
        success_rate = success_count/total_tests*100
        logger.info(f"\nì´ {total_tests}ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ {success_count}ê°œ ì„±ê³µ ({success_rate:.1f}%)")
        
        if success_count == total_tests:
            logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True
        else:
            logger.warning(f"âš ï¸ {total_tests - success_count}ê°œ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            if failed_tests:
                logger.warning(f"ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {', '.join(failed_tests)}")
                logger.warning("í•´ê²° ë°©ë²•:")
                for failed_test in failed_tests:
                    if "ì»¬ë ‰ì…˜" in failed_test:
                        logger.warning("  - Milvus ì„œë²„ ì—°ê²° ë° ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    elif "ê²€ìƒ‰" in failed_test:
                        logger.warning("  - ê²€ìƒ‰ ì¿¼ë¦¬ ë° ì¸ë±ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    elif "RAG" in failed_test:
                        logger.warning("  - ì„ë² ë”© ëª¨ë¸ ë° ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            logger.error("\nâŒ ê²€ìƒ‰ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        tester = SearchSystemTester()
        success = tester.run_all_tests()
        
        if success:
            logger.info("\nâœ… ê²€ìƒ‰ ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
            return 0
        else:
            logger.error("\nâŒ ê²€ìƒ‰ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            return 1
            
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return 1
    finally:
        # ì—°ê²° ì •ë¦¬
        try:
            if 'tester' in locals() and hasattr(tester, 'milvus_client'):
                tester.milvus_client.close()
        except Exception as e:
            logger.error(f"ì—°ê²° ì •ë¦¬ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)

# 🚀 RAG 검색 성능 개선 전략

## 📊 현재 성능 분석

### 현재 지표 (개선 대상)
- **Context Relevancy**: 0.288 (목표: 0.5+)
- **Answer Relevancy**: 0.127 (목표: 0.4+)  
- **전체 점수**: 0.616 (목표: 0.75+)

### 우수한 지표 (유지)
- **Context Precision**: 1.000 ✅
- **Context Recall**: 1.000 ✅
- **Faithfulness**: 0.665 (양호)

---

## 🎯 개선 전략 로드맵

## 1. 검색 알고리즘 최적화 (우선순위: 높음)

### 1.1 하이브리드 검색 구현
```python
# 현재: 순수 벡터 검색
results = retriever.retrieve(query, top_k=3)

# 개선안: 하이브리드 검색 (벡터 + BM25)
results = retriever.hybrid_retrieve(query, top_k=3)
```

**구현 계획:**
- BM25 키워드 검색과 벡터 검색 결합
- 가중치 조정: 벡터 70% + 키워드 30%
- 예상 Context Relevancy 향상: 0.288 → 0.45

### 1.2 쿼리 확장 (Query Expansion)
```python
# 동의어 및 관련 용어 자동 추가
original_query = "What are human rights?"
expanded_query = "What are human rights? civil rights political rights fundamental freedoms"
```

**구현 방법:**
- WordNet, 도메인 특화 시소러스 활용
- LLM 기반 쿼리 확장
- 예상 개선: Answer Relevancy +20%

### 1.3 Re-ranking 모델 도입
```python
# 1차: 벡터 검색으로 후보군 선별 (top_k=20)
candidates = vector_search(query, top_k=20)

# 2차: Cross-encoder로 정밀 재정렬
reranked = cross_encoder_rerank(query, candidates, top_k=3)
```

**예상 효과:**
- Context Relevancy: 0.288 → 0.55
- Answer Relevancy: 0.127 → 0.35

---

## 2. 임베딩 모델 개선 (우선순위: 중간)

### 2.1 도메인 특화 모델 활용
```python
# 현재 모델
model = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"

# 개선 후보들
candidates = [
    "sentence-transformers/all-MiniLM-L6-v2",  # 빠르고 효율적
    "intfloat/e5-large-v2",  # 최신 고성능 모델
    "BAAI/bge-large-en-v1.5",  # MTEB 상위 모델
]
```

### 2.2 Fine-tuning 검토
- 인권 도메인 데이터로 모델 미세조정
- Contrastive Learning 적용
- 예상 임베딩 품질 향상: 15-25%

---

## 3. 데이터 품질 개선 (우선순위: 높음)

### 3.1 청크 크기 최적화
```python
# 현재: 고정 크기 청크
current_strategy = "fixed_size_chunking"

# 개선안: 의미 기반 청크
improved_strategy = "semantic_chunking"  # 문단, 문장 단위
```

### 3.2 메타데이터 활용 강화
```python
# 현재 메타데이터
metadata = {
    "source_file": "amnesty_qa_generated",
    "chunk_type": "context"
}

# 개선된 메타데이터
enhanced_metadata = {
    "source_file": "amnesty_qa_generated",
    "chunk_type": "context",
    "topic": "human_rights_principles",  # 주제 분류
    "difficulty": "basic",               # 난이도
    "keywords": ["universality", "equality"],  # 핵심 키워드
    "section": "definitions"             # 섹션 분류
}
```

---

## 4. 답변 생성 개선 (우선순위: 중간)

### 4.1 프롬프트 엔지니어링
```python
# 현재 프롬프트 (기본)
current_prompt = "Answer the question based on the context."

# 개선된 프롬프트
improved_prompt = """
Based on the provided context, answer the question with:
1. Direct answer to the question
2. Key supporting evidence from the context
3. Clear, concise language
4. Relevant examples when appropriate

Question: {question}
Context: {context}

Answer:
"""
```

### 4.2 답변 검증 단계 추가
```python
# 생성된 답변의 관련성 검증
def validate_answer_relevancy(question, answer, context):
    relevancy_score = semantic_similarity(question, answer)
    factual_accuracy = check_facts_against_context(answer, context)
    return relevancy_score, factual_accuracy
```

---

## 5. 평가 및 모니터링 (우선순위: 중간)

### 5.1 A/B 테스트 프레임워크
```python
# 다양한 검색 전략 비교
strategies = {
    "baseline": "pure_vector_search",
    "hybrid": "vector_plus_bm25",
    "reranked": "vector_plus_crossencoder",
    "expanded": "query_expansion_plus_vector"
}

# 성능 비교 매트릭스
performance_matrix = compare_strategies(strategies, test_queries)
```

### 5.2 실시간 성능 모니터링
```python
# 성능 지표 추적
metrics_tracker = {
    "context_relevancy": [],
    "answer_relevancy": [], 
    "response_time": [],
    "user_satisfaction": []
}
```

---

## 🛠️ 구현 우선순위

### Phase 1 (즉시 구현 - 1주)
1. **하이브리드 검색 활성화**
   - `retriever.py`의 `hybrid_retrieve` 메서드 활용
   - BM25 + 벡터 검색 결합
   - 예상 개선: Context Relevancy +50%

2. **필터 조건 최적화**
   - 현재 데이터에 맞는 필터 조건 설정
   - `chunk_type="context"` 활용

### Phase 2 (단기 - 2-3주)
1. **Re-ranking 모델 구현**
   - Cross-encoder 기반 재정렬
   - Top-20 → Top-3 정밀 선별

2. **쿼리 확장 구현**
   - 동의어 및 관련어 자동 추가
   - LLM 기반 쿼리 개선

### Phase 3 (중기 - 1-2개월)
1. **임베딩 모델 업그레이드**
   - 최신 고성능 모델 테스트
   - 도메인 특화 Fine-tuning

2. **데이터 품질 개선**
   - 의미 기반 청킹
   - 메타데이터 강화

---

## 📈 예상 성능 개선

### 목표 지표 (3개월 후)
| 지표 | 현재 | 목표 | 개선율 |
|------|------|------|--------|
| Context Relevancy | 0.288 | 0.550 | +91% |
| Answer Relevancy | 0.127 | 0.400 | +215% |
| Faithfulness | 0.665 | 0.750 | +13% |
| **Overall Score** | **0.616** | **0.750** | **+22%** |

### 단계별 개선 예상
- **Phase 1**: 0.616 → 0.685 (+11%)
- **Phase 2**: 0.685 → 0.720 (+5%)  
- **Phase 3**: 0.720 → 0.750 (+4%)

---

## 🚀 빠른 실행 가이드

### 즉시 적용 가능한 개선
```python
# 1. 하이브리드 검색 활성화
config.retrieval['hybrid_search'] = True

# 2. 검색 결과 수 증가 (재정렬용)
config.retrieval['top_k'] = 10  # 기존 3 → 10

# 3. 임계값 조정
config.retrieval['similarity_threshold'] = 0.3  # 기존 0.5 → 0.3

# 4. 쿼리 최적화 활성화
results = retriever.retrieve(
    query, 
    enable_query_optimization=True,
    force_filter_expr=None
)
```

이 전략을 단계적으로 구현하면 RAG 시스템의 검색 성능을 크게 향상시킬 수 있을 것입니다.
